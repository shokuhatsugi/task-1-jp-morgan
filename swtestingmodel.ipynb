{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1s3mNI0rPKzHzXzm574lXfEBbLDEMhP2O",
      "authorship_tag": "ABX9TyPJ+iljJjWmxJ5sFBcS9Rl2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shokuhatsugi/task-1-jp-morgan/blob/main/swtestingmodel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preprocessing**\n"
      ],
      "metadata": {
        "id": "PFya_7yQy4th"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dRPBvEEwejaQ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/drive/MyDrive/Version_2/Version_2/Testing_carlease.csv\"\n",
        "data= pd.read_csv(path)\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "_odZMMBduQ5n",
        "outputId": "b2c787d0-c1b6-40c0-f668-f5756e537301"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   B_Req  R_Priority                              FP  Complexity  Time   Cost  \\\n",
              "0      1          94         TC#2027,TC#2928,TC#2053           3   4.0   60.0   \n",
              "1      2         197         TC#3269,TC#1752,TC#1042           3   4.0   60.0   \n",
              "2      3         163  TC#2843,TC#3332,TC#805,TC#2785           3   5.0   75.0   \n",
              "3      4         103          TC#1618,TC#953,TC#1368           1   4.0   20.0   \n",
              "4      5          70          TC#235,TC#3170,TC#2423           5   4.0  100.0   \n",
              "\n",
              "  Prioirty  Unnamed: 7  Unnamed: 8  Unnamed: 9  ...  Unnamed: 12  Unnamed: 13  \\\n",
              "0      Low         NaN         NaN         NaN  ...          NaN          NaN   \n",
              "1   Medium         NaN         NaN         NaN  ...          NaN          NaN   \n",
              "2      Low         NaN         NaN         NaN  ...          NaN          NaN   \n",
              "3     High         NaN         NaN         NaN  ...          NaN          NaN   \n",
              "4   Medium         NaN         NaN         NaN  ...          NaN          NaN   \n",
              "\n",
              "   Unnamed: 14  Unnamed: 15  Unnamed: 16  Unnamed: 17  Unnamed: 18  \\\n",
              "0          NaN          NaN          NaN          NaN          NaN   \n",
              "1          NaN          NaN          NaN          NaN          NaN   \n",
              "2          NaN          NaN          NaN          NaN          NaN   \n",
              "3          NaN          NaN          NaN          NaN          NaN   \n",
              "4          NaN          NaN          NaN          NaN          NaN   \n",
              "\n",
              "   Unnamed: 19  Unnamed: 20  Unnamed: 21  \n",
              "0          NaN          NaN          NaN  \n",
              "1          NaN          NaN          NaN  \n",
              "2          NaN          NaN          NaN  \n",
              "3          NaN          NaN          NaN  \n",
              "4          NaN          NaN          NaN  \n",
              "\n",
              "[5 rows x 22 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b2b3913c-f25b-43ef-8b7f-fd2371a75c77\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>B_Req</th>\n",
              "      <th>R_Priority</th>\n",
              "      <th>FP</th>\n",
              "      <th>Complexity</th>\n",
              "      <th>Time</th>\n",
              "      <th>Cost</th>\n",
              "      <th>Prioirty</th>\n",
              "      <th>Unnamed: 7</th>\n",
              "      <th>Unnamed: 8</th>\n",
              "      <th>Unnamed: 9</th>\n",
              "      <th>...</th>\n",
              "      <th>Unnamed: 12</th>\n",
              "      <th>Unnamed: 13</th>\n",
              "      <th>Unnamed: 14</th>\n",
              "      <th>Unnamed: 15</th>\n",
              "      <th>Unnamed: 16</th>\n",
              "      <th>Unnamed: 17</th>\n",
              "      <th>Unnamed: 18</th>\n",
              "      <th>Unnamed: 19</th>\n",
              "      <th>Unnamed: 20</th>\n",
              "      <th>Unnamed: 21</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>94</td>\n",
              "      <td>TC#2027,TC#2928,TC#2053</td>\n",
              "      <td>3</td>\n",
              "      <td>4.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>Low</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>197</td>\n",
              "      <td>TC#3269,TC#1752,TC#1042</td>\n",
              "      <td>3</td>\n",
              "      <td>4.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>Medium</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>163</td>\n",
              "      <td>TC#2843,TC#3332,TC#805,TC#2785</td>\n",
              "      <td>3</td>\n",
              "      <td>5.0</td>\n",
              "      <td>75.0</td>\n",
              "      <td>Low</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>103</td>\n",
              "      <td>TC#1618,TC#953,TC#1368</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>High</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>70</td>\n",
              "      <td>TC#235,TC#3170,TC#2423</td>\n",
              "      <td>5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>Medium</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 22 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b2b3913c-f25b-43ef-8b7f-fd2371a75c77')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b2b3913c-f25b-43ef-8b7f-fd2371a75c77 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b2b3913c-f25b-43ef-8b7f-fd2371a75c77');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7df8e793-dc3d-4237-afbd-ee068d745d58\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7df8e793-dc3d-4237-afbd-ee068d745d58')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7df8e793-dc3d-4237-afbd-ee068d745d58 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "QGATN7wFvCOr"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DjxGjeNkvHpH",
        "outputId": "acc617c9-8d32-4e37-f2eb-9848c5745058"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q keras"
      ],
      "metadata": {
        "id": "dJHtF1NfveVy"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras"
      ],
      "metadata": {
        "id": "d2Z4sx0JwFUD"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow"
      ],
      "metadata": {
        "id": "E34woG_AwIy4"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "yP2DdINYwe9Q"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ],
      "metadata": {
        "id": "WQvHple9w_qn"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "VurHYvbuxCnR"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_stories = data['B_Req'].astype(str).values\n",
        "test_cases = data['FP'].astype(str).values"
      ],
      "metadata": {
        "id": "sBNfz0bpx-jb"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(np.concatenate((user_stories, test_cases), axis=0))"
      ],
      "metadata": {
        "id": "CvOf9RjdyVLG"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "user_story_seqs = tokenizer.texts_to_sequences(user_stories)\n",
        "test_case_seqs = tokenizer.texts_to_sequences(test_cases)"
      ],
      "metadata": {
        "id": "XL9iyyMcyZRQ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_user_story_len = max(len(seq) for seq in user_story_seqs)\n",
        "max_test_case_len = max(len(seq) for seq in test_case_seqs)"
      ],
      "metadata": {
        "id": "Py8AA203ydfl"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_story_seqs = pad_sequences(user_story_seqs, maxlen=max_user_story_len, padding='post')\n",
        "test_case_seqs = pad_sequences(test_case_seqs, maxlen=max_test_case_len, padding='post')"
      ],
      "metadata": {
        "id": "-slTYLRtyoCs"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(tokenizer.word_index) + 1"
      ],
      "metadata": {
        "id": "c6bn60umytKW"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_target_data = np.zeros_like(test_case_seqs)\n",
        "decoder_target_data[:, :-1] = test_case_seqs[:, 1:]"
      ],
      "metadata": {
        "id": "na0ZN3hQywLU"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Definition**"
      ],
      "metadata": {
        "id": "z_z9suymzQb-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Attention"
      ],
      "metadata": {
        "id": "ESXtU0Ulyzlt"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 256\n",
        "lstm_units = 512"
      ],
      "metadata": {
        "id": "3-44_omxza2g"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_inputs = Input(shape=(max_user_story_len,))\n",
        "encoder_embedding = Embedding(vocab_size, embedding_dim, mask_zero=True)(encoder_inputs)\n",
        "encoder_lstm = LSTM(lstm_units, return_sequences=True, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(encoder_embedding)"
      ],
      "metadata": {
        "id": "0dgIrroqzdjH"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attention = Attention()\n",
        "attention_result = attention([encoder_outputs, encoder_outputs])"
      ],
      "metadata": {
        "id": "4j8uD7brziZK"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_inputs = Input(shape=(max_test_case_len,))\n",
        "decoder_embedding = Embedding(vocab_size, embedding_dim, mask_zero=True)(decoder_inputs)\n",
        "decoder_lstm = LSTM(lstm_units, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=[state_h, state_c])"
      ],
      "metadata": {
        "id": "AqQIuISEznf8"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_concat_input = tf.concat([attention_result, decoder_outputs], axis=-1)\n",
        "decoder_dense = Dense(vocab_size, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_concat_input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 553
        },
        "id": "VKCU7twnzroy",
        "outputId": "122100ec-fce0-4e5a-b37a-d7aaa4ad47b2"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Exception encountered when calling layer \"tf.concat\" (type TFOpLambda).\n\nDimension 1 in both shapes must be equal, but are 1 and 8. Shapes are [?,1] and [?,8]. for '{{node tf.concat/concat}} = ConcatV2[N=2, T=DT_FLOAT, Tidx=DT_INT32](Placeholder, Placeholder_1, tf.concat/concat/axis)' with input shapes: [?,1,512], [?,8,512], [] and with computed input tensors: input[2] = <-1>.\n\nCall arguments received by layer \"tf.concat\" (type TFOpLambda):\n  • values=['tf.Tensor(shape=(None, 1, 512), dtype=float32)', 'tf.Tensor(shape=(None, 8, 512), dtype=float32)']\n  • axis=-1\n  • name=concat",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-cdc479209c13>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdecoder_concat_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mattention_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_outputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdecoder_dense\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdecoder_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder_dense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_concat_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/tf_op_layer.py\u001b[0m in \u001b[0;36mhandle\u001b[0;34m(self, op, args, kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         ):\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mTFOpLambda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNOT_SUPPORTED\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer \"tf.concat\" (type TFOpLambda).\n\nDimension 1 in both shapes must be equal, but are 1 and 8. Shapes are [?,1] and [?,8]. for '{{node tf.concat/concat}} = ConcatV2[N=2, T=DT_FLOAT, Tidx=DT_INT32](Placeholder, Placeholder_1, tf.concat/concat/axis)' with input shapes: [?,1,512], [?,8,512], [] and with computed input tensors: input[2] = <-1>.\n\nCall arguments received by layer \"tf.concat\" (type TFOpLambda):\n  • values=['tf.Tensor(shape=(None, 1, 512), dtype=float32)', 'tf.Tensor(shape=(None, 8, 512), dtype=float32)']\n  • axis=-1\n  • name=concat"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, AdditiveAttention, Concatenate"
      ],
      "metadata": {
        "id": "pVYCIxFYzwmS"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 256\n",
        "lstm_units = 512"
      ],
      "metadata": {
        "id": "9FipClIH0lUr"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_inputs = Input(shape=(max_user_story_len,))\n",
        "encoder_embedding = Embedding(vocab_size, embedding_dim, mask_zero=True)(encoder_inputs)\n",
        "encoder_lstm = LSTM(lstm_units, return_sequences=True, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(encoder_embedding)"
      ],
      "metadata": {
        "id": "3k-Xz6y10oEe"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_inputs = Input(shape=(max_test_case_len,))\n",
        "decoder_embedding = Embedding(vocab_size, embedding_dim, mask_zero=True)(decoder_inputs)\n",
        "decoder_lstm = LSTM(lstm_units, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=[state_h, state_c])"
      ],
      "metadata": {
        "id": "PiOmr_R_0q93"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attention = AdditiveAttention()\n",
        "attention_result = attention([decoder_outputs, encoder_outputs])\n",
        "decoder_concat_input = Concatenate(axis=-1)([decoder_outputs, attention_result])"
      ],
      "metadata": {
        "id": "xH5z8cSb0vno"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_dense = Dense(vocab_size, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_concat_input)"
      ],
      "metadata": {
        "id": "cSi-ogo001Pu"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')"
      ],
      "metadata": {
        "id": "xaqGcWYY04fM"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit([user_story_seqs, test_case_seqs], decoder_target_data, epochs=100, batch_size=64, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4J_7Rkk08_g",
        "outputId": "29cb42b8-d8ff-416e-f0a0-77b9a1f89f1b"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "25/25 [==============================] - 31s 742ms/step - loss: 6.8524 - val_loss: 5.7852\n",
            "Epoch 2/100\n",
            "25/25 [==============================] - 15s 592ms/step - loss: 4.9264 - val_loss: 4.9885\n",
            "Epoch 3/100\n",
            "25/25 [==============================] - 15s 601ms/step - loss: 4.2719 - val_loss: 4.7973\n",
            "Epoch 4/100\n",
            "25/25 [==============================] - 15s 589ms/step - loss: 4.1162 - val_loss: 4.9102\n",
            "Epoch 5/100\n",
            "25/25 [==============================] - 15s 586ms/step - loss: 3.9874 - val_loss: 5.1008\n",
            "Epoch 6/100\n",
            "25/25 [==============================] - 15s 613ms/step - loss: 3.8461 - val_loss: 5.3693\n",
            "Epoch 7/100\n",
            "25/25 [==============================] - 16s 627ms/step - loss: 3.7333 - val_loss: 5.5900\n",
            "Epoch 8/100\n",
            "25/25 [==============================] - 15s 591ms/step - loss: 3.6008 - val_loss: 5.7821\n",
            "Epoch 9/100\n",
            "25/25 [==============================] - 15s 596ms/step - loss: 3.4574 - val_loss: 5.9538\n",
            "Epoch 10/100\n",
            "25/25 [==============================] - 15s 596ms/step - loss: 3.3183 - val_loss: 6.1219\n",
            "Epoch 11/100\n",
            "25/25 [==============================] - 15s 600ms/step - loss: 3.1800 - val_loss: 6.2956\n",
            "Epoch 12/100\n",
            "25/25 [==============================] - 15s 614ms/step - loss: 3.0438 - val_loss: 6.4237\n",
            "Epoch 13/100\n",
            "25/25 [==============================] - 15s 601ms/step - loss: 2.8754 - val_loss: 6.5782\n",
            "Epoch 14/100\n",
            "25/25 [==============================] - 15s 592ms/step - loss: 2.6522 - val_loss: 6.7132\n",
            "Epoch 15/100\n",
            "25/25 [==============================] - 15s 599ms/step - loss: 2.3224 - val_loss: 6.8260\n",
            "Epoch 16/100\n",
            "25/25 [==============================] - 15s 610ms/step - loss: 1.8423 - val_loss: 6.9521\n",
            "Epoch 17/100\n",
            "25/25 [==============================] - 16s 645ms/step - loss: 1.2930 - val_loss: 7.0719\n",
            "Epoch 18/100\n",
            "25/25 [==============================] - 15s 593ms/step - loss: 0.8246 - val_loss: 7.2410\n",
            "Epoch 19/100\n",
            "25/25 [==============================] - 15s 609ms/step - loss: 0.5093 - val_loss: 7.3829\n",
            "Epoch 20/100\n",
            "25/25 [==============================] - 14s 583ms/step - loss: 0.3119 - val_loss: 7.5261\n",
            "Epoch 21/100\n",
            "25/25 [==============================] - 15s 614ms/step - loss: 0.2066 - val_loss: 7.6669\n",
            "Epoch 22/100\n",
            "25/25 [==============================] - 15s 595ms/step - loss: 0.1492 - val_loss: 7.7841\n",
            "Epoch 23/100\n",
            "25/25 [==============================] - 16s 629ms/step - loss: 0.1185 - val_loss: 7.8576\n",
            "Epoch 24/100\n",
            "25/25 [==============================] - 16s 628ms/step - loss: 0.0991 - val_loss: 7.9725\n",
            "Epoch 25/100\n",
            "25/25 [==============================] - 15s 617ms/step - loss: 0.0845 - val_loss: 8.0174\n",
            "Epoch 26/100\n",
            "25/25 [==============================] - 16s 635ms/step - loss: 0.0727 - val_loss: 8.1265\n",
            "Epoch 27/100\n",
            "25/25 [==============================] - 17s 673ms/step - loss: 0.0620 - val_loss: 8.1481\n",
            "Epoch 28/100\n",
            "25/25 [==============================] - 16s 661ms/step - loss: 0.0543 - val_loss: 8.2315\n",
            "Epoch 29/100\n",
            "25/25 [==============================] - 15s 619ms/step - loss: 0.0477 - val_loss: 8.2698\n",
            "Epoch 30/100\n",
            "25/25 [==============================] - 15s 607ms/step - loss: 0.0421 - val_loss: 8.3307\n",
            "Epoch 31/100\n",
            "25/25 [==============================] - 15s 608ms/step - loss: 0.0373 - val_loss: 8.3679\n",
            "Epoch 32/100\n",
            "25/25 [==============================] - 15s 611ms/step - loss: 0.0338 - val_loss: 8.4245\n",
            "Epoch 33/100\n",
            "25/25 [==============================] - 15s 614ms/step - loss: 0.0308 - val_loss: 8.4456\n",
            "Epoch 34/100\n",
            "25/25 [==============================] - 15s 593ms/step - loss: 0.0278 - val_loss: 8.4872\n",
            "Epoch 35/100\n",
            "25/25 [==============================] - 16s 628ms/step - loss: 0.0251 - val_loss: 8.5273\n",
            "Epoch 36/100\n",
            "25/25 [==============================] - 15s 606ms/step - loss: 0.0230 - val_loss: 8.5566\n",
            "Epoch 37/100\n",
            "25/25 [==============================] - 14s 582ms/step - loss: 0.0213 - val_loss: 8.5949\n",
            "Epoch 38/100\n",
            "25/25 [==============================] - 14s 564ms/step - loss: 0.0197 - val_loss: 8.6229\n",
            "Epoch 39/100\n",
            "25/25 [==============================] - 15s 613ms/step - loss: 0.0182 - val_loss: 8.6574\n",
            "Epoch 40/100\n",
            "25/25 [==============================] - 14s 581ms/step - loss: 0.0170 - val_loss: 8.6883\n",
            "Epoch 41/100\n",
            "25/25 [==============================] - 16s 624ms/step - loss: 0.0158 - val_loss: 8.7222\n",
            "Epoch 42/100\n",
            "25/25 [==============================] - 15s 598ms/step - loss: 0.0148 - val_loss: 8.7452\n",
            "Epoch 43/100\n",
            "25/25 [==============================] - 14s 578ms/step - loss: 0.0139 - val_loss: 8.7724\n",
            "Epoch 44/100\n",
            "25/25 [==============================] - 16s 620ms/step - loss: 0.0131 - val_loss: 8.7997\n",
            "Epoch 45/100\n",
            "25/25 [==============================] - 16s 633ms/step - loss: 0.0124 - val_loss: 8.8235\n",
            "Epoch 46/100\n",
            "25/25 [==============================] - 15s 602ms/step - loss: 0.0117 - val_loss: 8.8455\n",
            "Epoch 47/100\n",
            "25/25 [==============================] - 15s 592ms/step - loss: 0.0110 - val_loss: 8.8703\n",
            "Epoch 48/100\n",
            "25/25 [==============================] - 14s 571ms/step - loss: 0.0105 - val_loss: 8.8883\n",
            "Epoch 49/100\n",
            "25/25 [==============================] - 16s 618ms/step - loss: 0.0099 - val_loss: 8.9106\n",
            "Epoch 50/100\n",
            "25/25 [==============================] - 16s 628ms/step - loss: 0.0094 - val_loss: 8.9309\n",
            "Epoch 51/100\n",
            "25/25 [==============================] - 15s 600ms/step - loss: 0.0090 - val_loss: 8.9508\n",
            "Epoch 52/100\n",
            "25/25 [==============================] - 16s 630ms/step - loss: 0.0085 - val_loss: 8.9718\n",
            "Epoch 53/100\n",
            "25/25 [==============================] - 15s 593ms/step - loss: 0.0082 - val_loss: 8.9919\n",
            "Epoch 54/100\n",
            "25/25 [==============================] - 15s 616ms/step - loss: 0.0078 - val_loss: 9.0097\n",
            "Epoch 55/100\n",
            "25/25 [==============================] - 15s 595ms/step - loss: 0.0074 - val_loss: 9.0265\n",
            "Epoch 56/100\n",
            "25/25 [==============================] - 16s 632ms/step - loss: 0.0071 - val_loss: 9.0451\n",
            "Epoch 57/100\n",
            "25/25 [==============================] - 15s 597ms/step - loss: 0.0068 - val_loss: 9.0634\n",
            "Epoch 58/100\n",
            "25/25 [==============================] - 15s 625ms/step - loss: 0.0065 - val_loss: 9.0808\n",
            "Epoch 59/100\n",
            "25/25 [==============================] - 15s 588ms/step - loss: 0.0063 - val_loss: 9.0974\n",
            "Epoch 60/100\n",
            "25/25 [==============================] - 16s 630ms/step - loss: 0.0060 - val_loss: 9.1123\n",
            "Epoch 61/100\n",
            "25/25 [==============================] - 15s 589ms/step - loss: 0.0058 - val_loss: 9.1301\n",
            "Epoch 62/100\n",
            "25/25 [==============================] - 15s 588ms/step - loss: 0.0056 - val_loss: 9.1453\n",
            "Epoch 63/100\n",
            "25/25 [==============================] - 14s 558ms/step - loss: 0.0054 - val_loss: 9.1610\n",
            "Epoch 64/100\n",
            "25/25 [==============================] - 16s 619ms/step - loss: 0.0051 - val_loss: 9.1774\n",
            "Epoch 65/100\n",
            "25/25 [==============================] - 14s 566ms/step - loss: 0.0049 - val_loss: 9.1935\n",
            "Epoch 66/100\n",
            "25/25 [==============================] - 14s 564ms/step - loss: 0.0048 - val_loss: 9.2093\n",
            "Epoch 67/100\n",
            "25/25 [==============================] - 14s 572ms/step - loss: 0.0046 - val_loss: 9.2248\n",
            "Epoch 68/100\n",
            "25/25 [==============================] - 16s 618ms/step - loss: 0.0044 - val_loss: 9.2387\n",
            "Epoch 69/100\n",
            "25/25 [==============================] - 15s 605ms/step - loss: 0.0043 - val_loss: 9.2535\n",
            "Epoch 70/100\n",
            "25/25 [==============================] - 15s 601ms/step - loss: 0.0041 - val_loss: 9.2663\n",
            "Epoch 71/100\n",
            "25/25 [==============================] - 16s 629ms/step - loss: 0.0040 - val_loss: 9.2780\n",
            "Epoch 72/100\n",
            "25/25 [==============================] - 15s 607ms/step - loss: 0.0039 - val_loss: 9.2939\n",
            "Epoch 73/100\n",
            "25/25 [==============================] - 15s 610ms/step - loss: 0.0037 - val_loss: 9.3074\n",
            "Epoch 74/100\n",
            "25/25 [==============================] - 16s 631ms/step - loss: 0.0036 - val_loss: 9.3208\n",
            "Epoch 75/100\n",
            "25/25 [==============================] - 15s 624ms/step - loss: 0.0035 - val_loss: 9.3352\n",
            "Epoch 76/100\n",
            "25/25 [==============================] - 16s 630ms/step - loss: 0.0034 - val_loss: 9.3510\n",
            "Epoch 77/100\n",
            "25/25 [==============================] - 15s 619ms/step - loss: 0.0033 - val_loss: 9.3642\n",
            "Epoch 78/100\n",
            "25/25 [==============================] - 15s 617ms/step - loss: 0.0032 - val_loss: 9.3756\n",
            "Epoch 79/100\n",
            "25/25 [==============================] - 15s 602ms/step - loss: 0.0031 - val_loss: 9.3891\n",
            "Epoch 80/100\n",
            "25/25 [==============================] - 15s 589ms/step - loss: 0.0030 - val_loss: 9.4016\n",
            "Epoch 81/100\n",
            "25/25 [==============================] - 16s 633ms/step - loss: 0.0029 - val_loss: 9.4126\n",
            "Epoch 82/100\n",
            "25/25 [==============================] - 15s 608ms/step - loss: 0.0028 - val_loss: 9.4246\n",
            "Epoch 83/100\n",
            "25/25 [==============================] - 16s 628ms/step - loss: 0.0027 - val_loss: 9.4373\n",
            "Epoch 84/100\n",
            "25/25 [==============================] - 15s 606ms/step - loss: 0.0027 - val_loss: 9.4498\n",
            "Epoch 85/100\n",
            "25/25 [==============================] - 16s 642ms/step - loss: 0.0026 - val_loss: 9.4575\n",
            "Epoch 86/100\n",
            "25/25 [==============================] - 15s 605ms/step - loss: 0.0025 - val_loss: 9.4721\n",
            "Epoch 87/100\n",
            "25/25 [==============================] - 15s 604ms/step - loss: 0.0024 - val_loss: 9.4810\n",
            "Epoch 88/100\n",
            "25/25 [==============================] - 15s 595ms/step - loss: 0.0024 - val_loss: 9.4949\n",
            "Epoch 89/100\n",
            "25/25 [==============================] - 16s 641ms/step - loss: 0.0023 - val_loss: 9.5045\n",
            "Epoch 90/100\n",
            "25/25 [==============================] - 15s 623ms/step - loss: 0.0022 - val_loss: 9.5154\n",
            "Epoch 91/100\n",
            "25/25 [==============================] - 16s 634ms/step - loss: 0.0022 - val_loss: 9.5272\n",
            "Epoch 92/100\n",
            "25/25 [==============================] - 17s 667ms/step - loss: 0.0021 - val_loss: 9.5368\n",
            "Epoch 93/100\n",
            "25/25 [==============================] - 15s 624ms/step - loss: 0.0021 - val_loss: 9.5477\n",
            "Epoch 94/100\n",
            "25/25 [==============================] - 15s 625ms/step - loss: 0.0020 - val_loss: 9.5567\n",
            "Epoch 95/100\n",
            "25/25 [==============================] - 15s 615ms/step - loss: 0.0020 - val_loss: 9.5694\n",
            "Epoch 96/100\n",
            "25/25 [==============================] - 16s 650ms/step - loss: 0.0019 - val_loss: 9.5784\n",
            "Epoch 97/100\n",
            "25/25 [==============================] - 16s 628ms/step - loss: 0.0019 - val_loss: 9.5901\n",
            "Epoch 98/100\n",
            "25/25 [==============================] - 15s 606ms/step - loss: 0.0018 - val_loss: 9.5990\n",
            "Epoch 99/100\n",
            "25/25 [==============================] - 15s 601ms/step - loss: 0.0018 - val_loss: 9.6082\n",
            "Epoch 100/100\n",
            "25/25 [==============================] - 16s 633ms/step - loss: 0.0017 - val_loss: 9.6184\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7d1e5eb9ffd0>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('test_case_generator.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fbiQGxG21A32",
        "outputId": "5cde177c-8528-4f06-c302-dfc9898e2e25"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluation and Inference**"
      ],
      "metadata": {
        "id": "Ov04VxCE7Fto"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_test_case(user_story, tokenizer, model, max_user_story_len, max_test_case_len):\n",
        "    user_story_seq = tokenizer.texts_to_sequences([user_story])\n",
        "    user_story_seq = pad_sequences(user_story_seq, maxlen=max_user_story_len, padding='post')\n",
        "\n",
        "    test_case_seq = np.zeros((1, max_test_case_len))\n",
        "    test_case_seq[0, 0] = tokenizer.word_index.get('<start>', 1)  # assuming <start> token exists\n",
        "\n",
        "    for i in range(1, max_test_case_len):\n",
        "        output_tokens = model.predict([user_story_seq, test_case_seq])\n",
        "        sampled_token_index = np.argmax(output_tokens[0, i-1, :])\n",
        "        test_case_seq[0, i] = sampled_token_index\n",
        "\n",
        "        if sampled_token_index == tokenizer.word_index.get('<end>', 2):  # assuming <end> token exists\n",
        "            break\n",
        "\n",
        "    test_case = tokenizer.sequences_to_texts(test_case_seq)\n",
        "    return ' '.join(test_case)"
      ],
      "metadata": {
        "id": "Q3qBJM047x5o"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_user_story = \"11\"\n",
        "test_case = generate_test_case(new_user_story, tokenizer, model, max_user_story_len, max_test_case_len)\n",
        "print(test_case)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ns3bAC0L8V30",
        "outputId": "2c2e2563-08d8-4fcc-930f-e70bf6da6f71"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "tc 118 tc 883 tc 2819\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_user_story = \"10\"\n",
        "test_case = generate_test_case(new_user_story, tokenizer, model, max_user_story_len, max_test_case_len)\n",
        "print(test_case)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BE-AXWO_9s7T",
        "outputId": "99611f17-84e7-49a2-b251-6344f6af4f75"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 96ms/step\n",
            "1/1 [==============================] - 0s 84ms/step\n",
            "1/1 [==============================] - 0s 86ms/step\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "tc 1783 tc 3377 tc 9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pcPxvpM--JKZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}